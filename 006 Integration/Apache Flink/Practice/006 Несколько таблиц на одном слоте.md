Чтобы распараллелить обработку двух таблиц в рамках одного слота и одной подписки, нужно изменить конфигурацию Flink CDC. Вот как это сделать:

## 1. Сначала внесем изменения в `config_prod.conf`:

```ini
# Увеличиваем параллелизм для обработки нескольких таблиц
flink.parallelism = 2

# Можно также настроить параметры для оптимизации параллельной обработки
# flink.cdc.source.parallelism = 2
```

## 2. Теперь создадим новый SQL скрипт для объединенного пайплайна:

```sql
-- flink-create-combined.sql
CREATE DATABASE IF NOT EXISTS `default_catalog`.`cdctest`;

-- 1. Создаем одну таблицу-источник для всех таблиц через CDC
CREATE TABLE IF NOT EXISTS `default_catalog`.`cdctest`.`combined_cdc_source` (
  `table_name` STRING NOT NULL METADATA FROM 'meta.table_name' VIRTUAL,
  `operation_ts` TIMESTAMP_LTZ(3) NOT NULL METADATA FROM 'meta.op_ts' VIRTUAL,
  `operation` STRING METADATA FROM 'meta.op_type' VIRTUAL,
  `constantid` INT NULL,
  `key` STRING NULL,
  `value` STRING NULL,
  `description` STRING NULL,
  `insertutcdate` TIMESTAMP NULL,
  `extraf` INT NULL,
  `extraf_1` INT NULL,
  `enumdescriptorid` INT NULL,
  `enumtypeid` INT NULL,
  `name` STRING NULL,
  `value_enum` BIGINT NULL,
  `languageresourceid` INT NULL
) WITH (
  'connector' = 'postgres-cdc',
  'password' = 'postgres',
  'database-name' = 'cdctest',
  'table-name' = 'constants|enumdescriptor',  -- Регулярное выражение для нескольких таблиц
  'debezium.slot.drop.on.stop' = 'true',
  'slot.name' = 'flink_cdc_demo_slot',
  'decoding.plugin.name' = 'pgoutput',
  'hostname' = 'xxxx',
  'port' = '5432',
  'username' = 'postgres',
  'schema-name' = 'dbo',
  'scan.incremental.snapshot.chunk.size' = '8096',
  'scan.incremental.snapshot.enabled' = 'true'
);

-- 2. Создаем снимки таблиц (если нужен точный контроль над схемой)
-- Таблица constants_src
CREATE VIEW constants_src_view AS
SELECT 
  `constantid`,
  `key`,
  `value`,
  `description`,
  `insertutcdate`,
  `extraf`,
  `extraf_1`,
  'constants' as source_table,
  `operation_ts`,
  `operation`
FROM `default_catalog`.`cdctest`.`combined_cdc_source`
WHERE `table_name` = 'constants' AND `constantid` IS NOT NULL;

-- Таблица enumdescriptor_src
CREATE VIEW enumdescriptor_src_view AS
SELECT 
  `enumdescriptorid`,
  `enumtypeid`,
  `name`,
  `value_enum` as `value`,
  `languageresourceid`,
  `insertutcdate`,
  'enumdescriptor' as source_table,
  `operation_ts`,
  `operation`
FROM `default_catalog`.`cdctest`.`combined_cdc_source`
WHERE `table_name` = 'enumdescriptor' AND `enumdescriptorid` IS NOT NULL;

-- 3. Создаем таблицы-приемники (оставляем как есть)
CREATE TABLE IF NOT EXISTS `default_catalog`.`cdctest`.`dbo__constants_sink` (
  `constantid` INT NOT NULL,
  `key` STRING NOT NULL,
  `value` STRING NULL,
  `description` STRING NULL,
  `insertutcdate` TIMESTAMP NULL,
  `extraf` INT NULL,
  `extraf_1` INT NULL,
  PRIMARY KEY(`constantid`) NOT ENFORCED
) WITH (
  'sink.parallelism' = '1',  -- Можно настроить параллелизм для каждой таблицы
  'sink.properties.strip_outer_array' = 'true',
  'load-url' = 'sl11-demostand-sr-01:8030',
  'sink.properties.format' = 'json',
  'database-name' = 'cdctest',
  'password' = 'xxx',
  'sink.buffer-flush.interval-ms' = '15000',
  'username' = 'root',
  'jdbc-url' = 'jdbc:mysql://sl11-demostand-sr-01:9030?useSSL=false&requireSSL=false',
  'sink.max-retries' = '10',
  'connector' = 'starrocks',
  'table-name' = 'dbo__constants'
);

CREATE TABLE IF NOT EXISTS `default_catalog`.`cdctest`.`dbo__enumdescriptor_sink` (
  `enumdescriptorid` INT NOT NULL,
  `enumtypeid` INT NOT NULL,
  `name` STRING NOT NULL,
  `value` BIGINT NOT NULL,
  `languageresourceid` INT NOT NULL,
  `insertutcdate` TIMESTAMP NULL,
  PRIMARY KEY(`enumdescriptorid`) NOT ENFORCED
) WITH (
  'sink.parallelism' = '1',
  'sink.properties.strip_outer_array' = 'true',
  'load-url' = 'sl11-demostand-sr-01:8030',
  'sink.properties.format' = 'json',
  'database-name' = 'cdctest',
  'sink.max-retries' = '10',
  'connector' = 'starrocks',
  'table-name' = 'dbo__enumdescriptor',
  'password' = 'xxx',
  'sink.buffer-flush.interval-ms' = '15000',
  'username' = 'root',
  'jdbc-url' = 'jdbc:mysql://sl11-demostand-sr-01:9030?useSSL=false&requireSSL=false'
);

-- 4. Вставляем данные в приемники
INSERT INTO `default_catalog`.`cdctest`.`dbo__constants_sink` 
SELECT 
  `constantid`,
  `key`,
  `value`,
  `description`,
  `insertutcdate`,
  `extraf`,
  `extraf_1`
FROM constants_src_view
WHERE `operation` IN ('r', 'c', 'u');  -- read, create, update

INSERT INTO `default_catalog`.`cdctest`.`dbo__enumdescriptor_sink` 
SELECT 
  `enumdescriptorid`,
  `enumtypeid`,
  `name`,
  `value`,
  `languageresourceid`,
  `insertutcdate`
FROM enumdescriptor_src_view
WHERE `operation` IN ('r', 'c', 'u');
```

## 3. Альтернативный вариант с раздельными источниками, но в одном задании:

```sql
-- flink-create-parallel.sql
CREATE DATABASE IF NOT EXISTS `default_catalog`.`cdctest`;

-- Создаем отдельные таблицы-источники, но используем один слот
CREATE TABLE IF NOT EXISTS `default_catalog`.`cdctest`.`dbo__constants_src` (
  `constantid` INT NOT NULL,
  `key` STRING NOT NULL,
  `value` STRING NULL,
  `description` STRING NULL,
  `insertutcdate` TIMESTAMP NULL,
  `extraf` INT NULL,
  `extraf_1` INT NULL,
  PRIMARY KEY(`constantid`) NOT ENFORCED
) WITH (
  'connector' = 'postgres-cdc',
  'password' = 'postgres',
  'database-name' = 'cdctest',
  'table-name' = 'constants',
  'debezium.slot.drop.on.stop' = 'true',
  'slot.name' = 'flink_cdc_demo_slot',
  'decoding.plugin.name' = 'pgoutput',
  'hostname' = 'xxxx',
  'port' = '5432',
  'username' = 'postgres',
  'schema-name' = 'dbo',
  'scan.incremental.snapshot.chunk.size' = '8096',
  'scan.startup.mode' = 'initial'
);

CREATE TABLE IF NOT EXISTS `default_catalog`.`cdctest`.`dbo__enumdescriptor_src` (
  `enumdescriptorid` INT NOT NULL,
  `enumtypeid` INT NOT NULL,
  `name` STRING NOT NULL,
  `value` BIGINT NOT NULL,
  `languageresourceid` INT NOT NULL,
  `insertutcdate` TIMESTAMP NULL,
  PRIMARY KEY(`enumdescriptorid`) NOT ENFORCED
) WITH (
  'connector' = 'postgres-cdc',
  'password' = 'postgres',
  'database-name' = 'cdctest',
  'table-name' = 'enumdescriptor',
  'debezium.slot.drop.on.stop' = 'true',
  'slot.name' = 'flink_cdc_demo_slot',  -- ОДИН И ТОТ ЖЕ СЛОТ
  'decoding.plugin.name' = 'pgoutput',
  'hostname' = 'xxxx',
  'port' = '5432',
  'username' = 'postgres',
  'schema-name' = 'dbo',
  'scan.incremental.snapshot.chunk.size' = '8096',
  'scan.startup.mode' = 'initial'
);

-- Таблицы-приемники остаются без изменений
CREATE TABLE IF NOT EXISTS `default_catalog`.`cdctest`.`dbo__constants_sink` (
  `constantid` INT NOT NULL,
  `key` STRING NOT NULL,
  `value` STRING NULL,
  `description` STRING NULL,
  `insertutcdate` TIMESTAMP NULL,
  `extraf` INT NULL,
  `extraf_1` INT NULL,
  PRIMARY KEY(`constantid`) NOT ENFORCED
) WITH (
  'sink.properties.strip_outer_array' = 'true',
  'load-url' = 'sl11-demostand-sr-01:8030',
  'sink.properties.format' = 'json',
  'database-name' = 'cdctest',
  'password' = 'xxx',
  'sink.buffer-flush.interval-ms' = '15000',
  'username' = 'root',
  'jdbc-url' = 'jdbc:mysql://sl11-demostand-sr-01:9030?useSSL=false&requireSSL=false',
  'sink.max-retries' = '10',
  'connector' = 'starrocks',
  'table-name' = 'dbo__constants'
);

CREATE TABLE IF NOT EXISTS `default_catalog`.`cdctest`.`dbo__enumdescriptor_sink` (
  `enumdescriptorid` INT NOT NULL,
  `enumtypeid` INT NOT NULL,
  `name` STRING NOT NULL,
  `value` BIGINT NOT NULL,
  `languageresourceid` INT NOT NULL,
  `insertutcdate` TIMESTAMP NULL,
  PRIMARY KEY(`enumdescriptorid`) NOT ENFORCED
) WITH (
  'sink.properties.strip_outer_array' = 'true',
  'load-url' = 'sl11-demostand-sr-01:8030',
  'sink.properties.format' = 'json',
  'database-name' = 'cdctest',
  'sink.max-retries' = '10',
  'connector' = 'starrocks',
  'table-name' = 'dbo__enumdescriptor',
  'password' = 'xxx',
  'sink.buffer-flush.interval-ms' = '15000',
  'username' = 'root',
  'jdbc-url' = 'jdbc:mysql://sl11-demostand-sr-01:9030?useSSL=false&requireSSL=false'
);

-- Параллельные вставки
INSERT INTO `default_catalog`.`cdctest`.`dbo__constants_sink` 
SELECT * FROM `default_catalog`.`cdctest`.`dbo__constants_src`;

INSERT INTO `default_catalog`.`cdctest`.`dbo__enumdescriptor_sink` 
SELECT * FROM `default_catalog`.`cdctest`.`dbo__enumdescriptor_src`;
```

## 4. Для запуска с увеличенным параллелизмом:

```bash
# Запуск Flink SQL с параллелизмом
./bin/sql-client.sh -f flink-create-parallel.sql \
  -Dparallelism.default=2 \
  -Dtable.exec.resource.default-parallelism=2 \
  -Dpipeline.default-parallelism=2

# Или в конфигурации Flink
# execution.parallelism: 2
# table.exec.resource.default-parallelism: 2
```

**Важные моменты:**

1. **Один слот**: Оба подхода используют один слот `flink_cdc_demo_slot` для обеих таблиц
2. **Параллелизм**: Можно настроить через `flink.parallelism` в конфиге или параметры запуска
3. **Ресурсы**: Убедитесь, что в PostgreSQL достаточно ресурсов для логической репликации
4. **Мониторинг**: Следите за использованием слота через `pg_replication_slots`

Первый вариант (с объединенным источником) более эффективен, так как использует одно подключение к PostgreSQL. Второй вариант проще в отладке и управлении.
