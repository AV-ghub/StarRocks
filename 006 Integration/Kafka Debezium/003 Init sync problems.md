> два вопроса  
> 1 как сделать снэпшот на млрдной таблице не убив продакшен?
> недавно обсуждали, что Flink CDC, используя дебезиум, может делать инкрементальные снэпшоты
> это же фича дебезиума? или это реализация на каких-то возможностях самого флинка?
> вообще, как наименее затратно (без блокировок прода) сделать новый снэпшот?
> 2 как работает дебезиум в случае ручного первоначального импорта данных?
> как он поймет, с какой позиции стартовать?
> ведь пока мы делаем и переносим вручную данные, на проде много чего произойдет
> а если мы на всякий случай возьмем изменения раньше начала времени ручного импорта, то почти гарантированно получим ошибки или неконсистентные данные в целевой базе

## **ВОПРОС 1: Как сделать снимок на млрдной таблице без убийства прода?**

Вы правы, это больная тема. К счастью, есть несколько стратегий:

### **Стратегии Debezium для больших таблиц:**

#### **1. `snapshot.mode: initial` (по умолчанию, НЕ подходит для больших таблиц)**
```json
"snapshot.mode": "initial"
```
- Блокирует таблицу `ACCESS SHARE LOCK` (слабая блокировка, но для млрд строк — это надолго)
- Читает через `SELECT * FROM huge_table`
- **Проблема:** Чтение занимает часы/дни, блокировка мешает автовакууму

#### **2. `snapshot.mode: never` + Ручной снимок (рекомендуется!)**
```json
"snapshot.mode": "never",
"topic.creation.default.replication.factor": 3
```
**Последовательность действий:**
1. Запускаем Debezium с `never` — он начинает слушать **новые изменения с этого момента**, но не делает снимок
2. Параллельно делаем снимок своими средствами:
   - **pg_dump с `--jobs=N`** для параллельного экспорта
   - **COPY TO** с чанками
   - **Инструменты типа pgcopydb, wal2json**
3. Загружаем снимок в StarRocks
4. Debezium тем временем накопил дельты в Kafka
5. Запускаем Routine Load, который сначала прочитает накопленные дельты, потом перейдет в реальное время

#### **3. `snapshot.mode: exported` (PostgreSQL specific)**
```json
"snapshot.mode": "exported"
```
- Использует механизм `pg_export_snapshot()`
- **Как работает:**
  1. Создается транзакция с `REPEATABLE READ`
  2. Экспортируется идентификатор снапшота
  3. Таблицы **не блокируются** на всё время чтения
  4. Другие транзакции видят данные на момент начала снапшота
- **Минус:** Требует много памяти для long-running транзакции

#### **4. Incremental Snapshot (фича Debezium 1.6+) — то, что вы упомянули!**
```json
"snapshot.mode": "initial",
"snapshot.mode.class": "io.debezium.snapshot.IncrementalSnapshotter"
```
**Это именно фича Debezium**, которую потом используют Flink CDC, Kafka Connect и другие.

**Как работает инкрементальный снимок:**
```
Шаг 1: Начать снимок
    ↓
Шаг 2: Определить границы (MIN(id), MAX(id))
    ↓
Шаг 3: Разбить на чанки по 10K записей
    ↓
Шаг 4: Для каждого чанка:
    ├── Взять границы чанка (id BETWEEN X AND Y)
    ├── Запросить эти строки
    ├── Отправить в Kafka как события 'r' (read)
    ├── Параллельно продолжать слушать новые изменения!
    └── Запомнить, какие изменения произошли в этом диапазоне
    ↓
Шаг 5: Применить накопленные изменения поверх снапшота
    ↓
Шаг 6: Продолжить CDC в реальном времени
```

**Магия в том, что:**
- Чтение идет **чанками**, а не всей таблицей
- **Нет долгих блокировок**
- Можно **паузировать и возобновлять**
- **Параллельно** идут новые изменения, которые корректно применяются

**Flink CDC** просто использует эту возможность Debezium, добавляя свою оркестрацию.

### **Моя рекомендация для прода с млрдными таблицами:**
1. **Для инициализации:** `snapshot.mode: never` + pg_dump с чанками
2. **Для пересинка (если отстал):** Incremental snapshot
3. **Постоянно:** Дельта-изменения в реальном времени

---

## **ВОПРОС 2: Ручной импорт + CDC — как не сломать консистентность?**

Это классическая проблема **"cut-over"** — момент переключения со снимка на дельту. Решение — **LSN-based синхронизация**.

### **Проблема, которую вы описали:**
```
Время 10:00: Делаем pg_dump
Время 10:05: В продакшене UPDATE строки X
Время 10:30: Загружаем дамп в StarRocks
Время 10:35: Запускаем Debezium
Время 10:36: Debezium читает UPDATE из 10:05
Результат: В StarRocks старая версия из дампа + UPDATE поверх = неконсистентность!
```

### **Решение: Точная синхронизация по LSN (Log Sequence Number)**

**LSN** — это уникальный идентификатор позиции в WAL PostgreSQL. Это как "номер записи в журнале".

#### **План действий:**

**Шаг 1: Подготовка**
```sql
-- 1. Создаем слот репликации вручную (чтобы Debezium потом переиспользовал)
SELECT * FROM pg_create_logical_replication_slot(
  'debezium_manual_sync',
  'pgoutput'
);

-- 2. Фиксируем текущую позицию LSN ДО начала дампа
SELECT pg_current_wal_lsn() AS start_lsn;
-- Записываем куда-то: 0/1567D88
```

**Шаг 2: Параллельное выполнение**
```
┌─────────────────────────────────────────────────────────────┐
│ Время 10:00                                                 │
├─────────────────────────────────────────────────────────────┤
│ 1. start_lsn = 0/1567D88                                    │
│ 2. Запускаем pg_dump (снимок на момент ~start_lsn)          │
│ 3. Сразу запускаем Debezium с конфигом:                     │
│    "snapshot.mode": "never",                                │
│    "slot.name": "debezium_manual_sync",                     │
│    "plugin.name": "pgoutput"                                │
└─────────────────────────────────────────────────────────────┘
    ↓ (Debezium начинает копить дельты с start_lsn в Kafka)
┌─────────────────────────────────────────────────────────────┐
│ Время 10:30                                                 │
├─────────────────────────────────────────────────────────────┤
│ 1. Загружаем дамп в StarRocks                               │
│ 2. Проверяем, что Debezium жив и пишет в Kafka              │
└─────────────────────────────────────────────────────────────┘
```

**Шаг 3: Точная настройка StarRocks Routine Load**

Вот тут магия — нужно сказать StarRocks: "Читай с момента start_lsn, но пропусти первые N сообщений":

```sql
-- Создаем Routine Load, но НЕ запускаем сразу
CREATE ROUTINE LOAD mydb.users_load ON users
PROPERTIES
(
  "desired_concurrent_number" = "3",
  "format" = "json"
)
FROM KAFKA
(
  "kafka_broker_list" = "kafka:9092",
  "kafka_topic" = "mycluster.public.users",
  -- ВАЖНО: Берем offset, соответствующий start_lsn
  "property.kafka_default_offsets" = "OFFSET_TIMESTAMP:1678886400000"
);
```

**Проблема:** Как найти нужный offset в Kafka, соответствующий `start_lsn`?

#### **Решение A: Использовать `txid_current()` + Timestamp mapping**

```sql
-- Перед дампом:
SELECT 
  pg_current_wal_lsn() as start_lsn,
  txid_current() as start_txid,
  extract(epoch from now()) * 1000 as start_timestamp_ms;
-- Записываем: 0/1567D88, 12345, 1678886400000
```

Затем в Routine Load используем `OFFSET_TIMESTAMP:1678886400000`. Kafka найдет первое сообщение после этого времени.

#### **Решение B: Debezium вставляет метаданные**

Debezium в каждое сообщение вставляет:
```json
{
  "source": {
    "lsn": 1234567,
    "txId": 12345,
    "ts_ms": 1678886400000
  }
}
```

Можно сделать так:
1. Запустить Routine Load с самого начала (`OFFSET_BEGINNING`)
2. В StarRocks фильтровать: `WHERE source.lsn > 1234567`
3. Но это неэффективно — придется пропустить много данных

#### **Решение C: Наилучшее — Kafka Connect SMT + Header routing**

Настраиваем Debezium с **Single Message Transform**:

```json
{
  "transforms": "router",
  "transforms.router.type": "io.debezium.transforms.ByLogicalTableRouter",
  "transforms.router.topic.regex": "(.*)",
  "transforms.router.topic.replacement": "$1_cdc",
  "transforms.router.key.field.name": "__debezium_source_lsn"
}
```

А в StarRocks создаем **два Routine Load**:
1. Для начального снимка (данные до `start_lsn`)
2. Для CDC (данные после `start_lsn`)

### **Идеальный алгоритм:**

```python
# Псевдокод идеальной миграции
def migrate_with_consistency():
    # 1. Подготовительный этап
    create_replication_slot('debezium_slot')
    start_lsn = get_current_lsn()  # 0/1567D88
    start_time = current_time()
    
    # 2. Параллельный запуск
    thread1 = start_debezium(slot='debezium_slot', snapshot_mode='never')
    thread2 = run_pg_dump(consistent_at_lsn=start_lsn)
    
    # 3. Загрузка снимка
    load_dump_to_starrocks()
    
    # 4. Находим нужный offset в Kafka
    # Ищем первое сообщение с source.ts_ms > start_time
    target_offset = find_kafka_offset_for_timestamp(start_time)
    
    # 5. Запускаем Routine Load с точного offset
    create_routine_load(start_offset=target_offset)
    
    # 6. Валидация
    validate_data_consistency()
```

### **Что делать, если уже накопились дельты во время дампа?**

Если Debezium уже накопил 1ТБ дельт в Kafka пока мы делали дамп:

1. **Фильтровать по LSN в StarRocks:**
```sql
-- В Routine Load добавляем условие
WHERE CAST(source.lsn AS BIGINT) > 1234567
```

2. **Использовать временную таблицу-буфер:**
   - Загружаем ВСЕ данные из Kafka во временную таблицу
   - Делаем `MERGE` с основной, используя LSN как версию
   - `DELETE` где LSN < start_lsn

3. **Лучше всего:** Использовать **Debezium signaling tables**:
```sql
-- Отправить сигнал Debezium приостановиться
INSERT INTO debezium_signal (id, type, data) 
VALUES ('pause-1', 'pause-snapshot', '{"data-collections": ["public.users"]}');
```

### **Выводы:**

1. **Всегда фиксируйте LSN перед дампом** — это ваша точка консистентности
2. **Используйте `snapshot.mode: never`** для больших таблиц
3. **Синхронизируйте через timestamp → offset mapping** в Kafka
4. **Валидируйте** после переключения (сравните COUNT, CHECKSUM)
5. **Имейте план отката** — возможность перезапустить миграцию

**Самый безопасный паттерн:** Сделать дамп → Загрузить в staging → Запустить CDC → Синхронизировать → Переключиться на production.
