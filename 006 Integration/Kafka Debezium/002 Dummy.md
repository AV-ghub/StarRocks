Документация часто упускает "магию запуска".  
Разберем, как физически оживает цепочка синхронизации.  

Представьте себе конвейер на заводе:

```
[Склад деталей (PostgreSQL)] → [Робот-захват (Debezium)] → [Конвейерная лента (Kafka)] → [Сборочный робот (StarRocks)]
```

---

### **ШАГ 0: ПРЕДПОЛОЖЕНИЯ**
У вас уже установлены и работают:
1. PostgreSQL (с логической репликацией `wal_level=logical`)
2. Apache Kafka с Kafka Connect (в distributed mode)
3. StarRocks

---

### **ШАГ 1: "ПРИСТЕГИВАЕМ РОБОТА-ЗАХВАТА" (Debezium) к КОНВЕЙЕРУ (Kafka)**

**Что делаем:** Говорим Kafka Connect'у: "У нас есть новый работник-коннектор, вот его инструкция".

**Как физически:**
1. Кладем JAR Debezium в директорию плагинов Kafka Connect (например, `/usr/share/kafka/plugins/`)
2. **Перезапускаем** сервис Kafka Connect, чтобы он "увидел" нового работника
3. Отправляем HTTP-запрос на REST API Kafka Connect (обычно порт 8083):

```bash
POST http://kafka-connect:8083/connectors
Content-Type: application/json

{
  "name": "debezium-postgres-connector",  # Уникальное имя работника
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "database.hostname": "postgres-host",
    "database.port": "5432",
    "database.user": "debezium",
    "database.password": "secret",
    "database.dbname": "mydb",
    "plugin.name": "pgoutput",
    "slot.name": "debezium_slot",          # Слот репликации в PostgreSQL
    "topic.prefix": "mycluster",           # Префикс для топиков
    "table.include.list": "public.users,public.orders"  # Какие таблицы слушать
  }
}
```

**Что происходит внутри:**
1. Kafka Connect создает **отдельный процесс (JVM)** для этого коннектора
2. Debezium внутри этого процесса подключается к PostgreSQL и создает:
   - **Слот логической репликации** (если не существует)
   - **Первоначальный снимок** (snapshot) — об этом подробнее ниже
3. Начинает слушать изменения из слота репликации

**Важно:** Пока вы не отправите этот HTTP-запрос — **ничего не работает**. JAR в директории — просто набор инструментов в ящике. Запрос на API — это команда "начать работу".

---

### **ШАГ 2: "НАЧАЛЬНЫЙ СНИМОК" — КАК ДЕБЕЗИУМ ПОЛУЧАЕТ СУЩЕСТВУЮЩИЕ ДАННЫЕ**

Это критический момент. Есть несколько стратегий (задаются в конфиге):

#### **Стратегия 1: Initial snapshot (по умолчанию)**
```
"snapshot.mode": "initial"
```
**Что происходит:**
1. Debezium **блокирует таблицу на чтение** (не на запись! `ACCESS SHARE LOCK` — слабая блокировка)
2. Считывает все строки таблицы через `SELECT * FROM table`
3. Для каждой строки генерирует событие **`op: 'r'` (read)** и отправляет в Kafka
4. **После завершения снимка** переключается на чтение изменений из WAL в реальном времени
5. Разблокирует таблицу

**Плюсы:** Автоматически, ничего не пропускает
**Минусы:** Медленно для больших таблиц, блокировка (хоть и слабая)

#### **Стратегия 2: No snapshot (только новые изменения)**
```
"snapshot.mode": "never"
```
**Используется, когда:** Вы уже сделали снимок другими средствами (pg_dump) и загрузили его в StarRocks. Debezium будет слушать **только новые изменения с этого момента**.

#### **Стратегия 3: Снимок на основе экспорта (рекомендуется для больших таблиц)**
```
"snapshot.mode": "exported"
```
Debezium использует механизм экспорта PostgreSQL. Меньше влияет на производительность.

---

### **ШАГ 3: "КОНВЕЙЕР ЗАПУЩЕН" — ПОТОК ИЗМЕНЕНИЙ В РЕАЛЬНОМ ВРЕМЕНИ**

После снимка начинается непрерывная работа:

1. **В PostgreSQL:** При каждом `INSERT/UPDATE/DELETE` запись попадает в WAL
2. **Debezium:** 
   - Постоянно опрашивает слот репликации: "Есть новые данные в WAL?"
   - Получает байты из WAL, декодирует их в события
   - Отправляет события в соответствующий топик Kafka
   - **Подтверждает** PostgreSQL: "Я получил данные до позиции X" (это важно!)

3. **В Kafka:** Появляются сообщения вида:
```json
// Топик: mycluster.public.users
{
  "key": {"id": 123},
  "value": {
    "op": "u",
    "before": {"id": 123, "name": "Ivan", "age": 30},
    "after": {"id": 123, "name": "Ivan", "age": 31},
    "source": {"ts_ms": 1678886400000, "table": "users"}
  }
}
```

**Важно:** Это уже работает автоматически! Коннектор Debezium — это долгоживущий процесс, который работает, пока вы его не остановите.

---

### **ШАГ 4: "СБОРОЧНЫЙ РОБОТ" (StarRocks) ПОДКЛЮЧАЕТСЯ К КОНВЕЙЕРУ**

Теперь нужно сказать StarRocks: "Читай с этого конвейера и собирай детали в изделия".

**Как физически:**
1. Подключаемся к StarRocks через MySQL-клиент
2. Создаем **Routine Load Job**:

```sql
CREATE ROUTINE LOAD mydb.users_load ON users
COLUMNS(id, name, age, __op = op, __deleted = if(op='d', true, false))
PROPERTIES
(
  "desired_concurrent_number" = "3",
  "format" = "json",
  "jsonpaths" = "['$.after.id','$.after.name','$.after.age','$.op']"
)
FROM KAFKA
(
  "kafka_broker_list" = "kafka1:9092,kafka2:9092",
  "kafka_topic" = "mycluster.public.users",
  "property.kafka_default_offsets" = "OFFSET_BEGINNING"
);
```

**Что происходит:**
1. StarRocks создает **фоновую задачу (job)**, которая постоянно опрашивает Kafka
2. Для каждого сообщения:
   - Извлекает данные из `$.after.*` (или `$.before.*` для удалений)
   - Применяет простые трансформации (например, `__deleted = if(op='d', true, false)`)
   - Вставляет/обновляет данные в таблицу `users`
3. **Сохраняет offset** — на каком сообщении он остановился

**Важно:** Эта задача тоже работает постоянно в фоне!

---

### **ШАГ 5: ЧТО ПРОИСХОДИТ ПРИ СБОЯХ**

#### **Если упал Debezium:**
1. PostgreSQL хранит WAL, пока слот репликации не подтвердит получение
2. При перезапуске Debezium подключается к слоту и продолжает с того же места (благодаря offset в слоте)

#### **Если упал Kafka:**
1. Debezium не сможет отправлять сообщения и тоже остановится
2. PostgreSQL будет накапливать WAL (пока не заполнится диск!)
3. После восстановления Kafka всё продолжится

#### **Если упал StarRocks:**
1. Kafka будет накапливать сообщения
2. При восстановлении StarRocks продолжит чтение с того offset, где остановился

---

### **АНАЛОГИЯ С АВТОМОБИЛЕМ:**

1. **JAR в директории** = инструменты в гараже (лежат, но не работают)
2. **HTTP-запрос на создание коннектора** = поворот ключа зажигания
3. **Initial snapshot** = заводская сборка машины (первый запуск)
4. **CDC в реальном времени** = работающий двигатель на холостом ходу
5. **Routine Load Job** = включенная АКПП (автоматически передает движение на колеса)
6. **Offsets** = одометр (помнит, сколько проехали)

---

### **ЧТО ЗАПУСКАТЬ РУКАМИ И КОГДА:**

1. **Один раз:** Отправить HTTP-запрос для создания Debezium коннектора
2. **Один раз:** Создать Routine Load Job в StarRocks
3. **При изменении структуры таблицы:** Может потребоваться пересоздание коннектора/job
4. **При перезапуске системы:** Сервисы стартуют автоматически (через systemd/docker)

**Главный секрет:** После первоначальной настройки **всё работает автоматически**. Вы просто вставляете строку в PostgreSQL → через несколько секунд она появляется в StarRocks. Вся "магия" в том, что:
- Debezium — это **демон**, который постоянно слушает PostgreSQL
- Routine Load — это **демон**, который постоянно читает из Kafka
